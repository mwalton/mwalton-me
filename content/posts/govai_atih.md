---
title: Governing AI
date: 2023-09-11
transclude: "false"
---
![govai](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda4dfb9d-130d-4ec0-8fdb-27fddf8487bf_2160x1080.png)

>_Q: Why do you want breaks on a car? A: So you can (safely) go fast._

In conversation with [The UN Tech Envoy](https://www.un.org/techenvoy/) and [Areeq Chowdhury](https://www.csap.cam.ac.uk/network/areeq-chowdhury/): Panelists discussed viewing AI from a human rights lens, risks of weaponization and policy diversity to respect societal context. The speakers advocated for cross-functional governance and human-rights focused, independent algorithmic impacts assessments. ML is high-impact and high risk enough to have collaboration trump competition. 

>_By focusing on bias within technology, we risk setting the success criteria as accurate tools of oppression, whereas we should be asking "do we want these tools of oppression in the first place?"_ —Areeq Chowdhury


